{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7977b244",
   "metadata": {},
   "source": [
    "Here we have tried modelling a CNN on a dataset of drug-side effect pair. But we only consider side effect groups which is 23 labels. And this is a multi-label classification problem where dataset is highly skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32e01a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88fc4cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>STITCH</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Blood and lymphatic system disorders</th>\n",
       "      <th>Cardiac disorders</th>\n",
       "      <th>Congenital, familial and genetic disorders</th>\n",
       "      <th>Ear and labyrinth disorders</th>\n",
       "      <th>Endocrine disorders</th>\n",
       "      <th>Eye disorders</th>\n",
       "      <th>Gastrointestinal disorders</th>\n",
       "      <th>...</th>\n",
       "      <th>Musculoskeletal and connective tissue disorders</th>\n",
       "      <th>Neoplasms benign, malignant and unspecified (incl cysts and polyps)</th>\n",
       "      <th>Nervous system disorders</th>\n",
       "      <th>Pregnancy, puerperium and perinatal conditions</th>\n",
       "      <th>Psychiatric disorders</th>\n",
       "      <th>Renal and urinary disorders</th>\n",
       "      <th>Reproductive system and breast disorders</th>\n",
       "      <th>Respiratory, thoracic and mediastinal disorders</th>\n",
       "      <th>Skin and subcutaneous tissue disorders</th>\n",
       "      <th>Vascular disorders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>CID000000143</td>\n",
       "      <td>Nc1nc(=O)c2c([nH]1)NCC(CNc1ccc(C(=O)NC(CCC(=O)O)C(=O)O)cc1)N2C=O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>CID000000772</td>\n",
       "      <td>CC(=O)NC1C(O)OC(COS(=O)(=O)O)C(OC2OC(C(=O)O)C(OC3OC(CO)C(OC4OC(C(=O)O)C(O)C(O)C4OS(=O)(=O)O)C(OS(=O)(=O)O)C3NS(=O)(=O)O)C(O)C2OS(=O)(=O)O)C1O</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>CID000002019</td>\n",
       "      <td>Cc1c2oc3c(C)ccc(C(=O)NC4C(=O)NC(C(C)C)C(=O)N5CCCC5C(=O)N(C)CC(=O)N(C)C(C(C)C)C(=O)OC4C)c3nc-2c(C(=O)NC2C(=O)NC(C(C)C)C(=O)N3CCCC3C(=O)N(C)CC(=O)N(C)C(C(C)C)C(=O)OC2C)c(N)c1=O</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>CID000002156</td>\n",
       "      <td>CCCCc1oc2ccccc2c1C(=O)c1cc(I)c(OCC[NH+](CC)CC)c(I)c1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>CID000002162</td>\n",
       "      <td>CCOC(=O)C1=C(COCCN)NC(C)=C(C(=O)OC)C1c1ccccc1Cl</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>1549</td>\n",
       "      <td>CID070683024</td>\n",
       "      <td>COCCOC(=O)NCC(=O)N[C@H]1[C@H]([C@H](O)[C@H](O)CO)O[C@@](OC[C@H]2O[C@H](O[C@H](C)[C@H](N)C(=O)O)[C@H](NC(C)=O)[C@@H](O)[C@H]2O)(C(=O)O)C[C@@H]1O</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>1550</td>\n",
       "      <td>CID070685014</td>\n",
       "      <td>C[C@@H]1NC(=O)[C@@H]2CCCN2C(=O)[C@H](CC(N)=O)NC(=O)[C@@H]2CSSC[C@@H](N)C(=O)N[C@H]3CSSC[C@H](NC1=O)C(=O)N[C@@H]([C@@H](C)O)C(=O)NCC(=O)N[C@H](C(=O)N[C@@H](Cc1ccc(O)cc1)C(=O)O)CSSC[C@H](NC(=O)[C@H](Cc1ccc(O)cc1)NC(=O)[C@H](CCC(=O)O)NC3=O)C(=O)N2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>1552</td>\n",
       "      <td>CID070788982</td>\n",
       "      <td>NCCCC[C@@H]1NC(=O)[C@@H](Cc2c[nH]c3ccccc23)NC(=O)[C@H](c2ccccc2)NC(=O)[C@@H]2C[C@@H](OC(=O)NCCN)CN2C(=O)[C@H](Cc2ccccc2)NC(=O)[C@H](Cc2ccc(OCc3ccccc3)cc2)NC1=O.N[C@@H](CC(=O)O)C(=O)O.N[C@@H](CC(=O)O)C(=O)O</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>1553</td>\n",
       "      <td>CID071306410</td>\n",
       "      <td>CC(C)(C)NCC(O)COc1nsnc1N1CCOCC1.CCNC1CN(CCCOC)S(=O)(=O)c2sc(S(N)(=O)=O)cc21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>1554</td>\n",
       "      <td>CID071306834</td>\n",
       "      <td>CCCN(CCOc1c(Cl)cc(Cl)cc1Cl)C(=O)n1ccnc1.O=S(=O)([O-])C(I)I.[Na+]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>825 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0        STITCH  \\\n",
       "0             2  CID000000143   \n",
       "1            25  CID000000772   \n",
       "2            50  CID000002019   \n",
       "3            66  CID000002156   \n",
       "4            70  CID000002162   \n",
       "..          ...           ...   \n",
       "820        1549  CID070683024   \n",
       "821        1550  CID070685014   \n",
       "822        1552  CID070788982   \n",
       "823        1553  CID071306410   \n",
       "824        1554  CID071306834   \n",
       "\n",
       "                                                                                                                                                                                                                                                   SMILES  \\\n",
       "0                                                                                                                                                                                        Nc1nc(=O)c2c([nH]1)NCC(CNc1ccc(C(=O)NC(CCC(=O)O)C(=O)O)cc1)N2C=O   \n",
       "1                                                                                                           CC(=O)NC1C(O)OC(COS(=O)(=O)O)C(OC2OC(C(=O)O)C(OC3OC(CO)C(OC4OC(C(=O)O)C(O)C(O)C4OS(=O)(=O)O)C(OS(=O)(=O)O)C3NS(=O)(=O)O)C(O)C2OS(=O)(=O)O)C1O   \n",
       "2                                                                          Cc1c2oc3c(C)ccc(C(=O)NC4C(=O)NC(C(C)C)C(=O)N5CCCC5C(=O)N(C)CC(=O)N(C)C(C(C)C)C(=O)OC4C)c3nc-2c(C(=O)NC2C(=O)NC(C(C)C)C(=O)N3CCCC3C(=O)N(C)CC(=O)N(C)C(C(C)C)C(=O)OC2C)c(N)c1=O   \n",
       "3                                                                                                                                                                                                    CCCCc1oc2ccccc2c1C(=O)c1cc(I)c(OCC[NH+](CC)CC)c(I)c1   \n",
       "4                                                                                                                                                                                                         CCOC(=O)C1=C(COCCN)NC(C)=C(C(=O)OC)C1c1ccccc1Cl   \n",
       "..                                                                                                                                                                                                                                                    ...   \n",
       "820                                                                                                       COCCOC(=O)NCC(=O)N[C@H]1[C@H]([C@H](O)[C@H](O)CO)O[C@@](OC[C@H]2O[C@H](O[C@H](C)[C@H](N)C(=O)O)[C@H](NC(C)=O)[C@@H](O)[C@H]2O)(C(=O)O)C[C@@H]1O   \n",
       "821  C[C@@H]1NC(=O)[C@@H]2CCCN2C(=O)[C@H](CC(N)=O)NC(=O)[C@@H]2CSSC[C@@H](N)C(=O)N[C@H]3CSSC[C@H](NC1=O)C(=O)N[C@@H]([C@@H](C)O)C(=O)NCC(=O)N[C@H](C(=O)N[C@@H](Cc1ccc(O)cc1)C(=O)O)CSSC[C@H](NC(=O)[C@H](Cc1ccc(O)cc1)NC(=O)[C@H](CCC(=O)O)NC3=O)C(=O)N2   \n",
       "822                                         NCCCC[C@@H]1NC(=O)[C@@H](Cc2c[nH]c3ccccc23)NC(=O)[C@H](c2ccccc2)NC(=O)[C@@H]2C[C@@H](OC(=O)NCCN)CN2C(=O)[C@H](Cc2ccccc2)NC(=O)[C@H](Cc2ccc(OCc3ccccc3)cc2)NC1=O.N[C@@H](CC(=O)O)C(=O)O.N[C@@H](CC(=O)O)C(=O)O   \n",
       "823                                                                                                                                                                           CC(C)(C)NCC(O)COc1nsnc1N1CCOCC1.CCNC1CN(CCCOC)S(=O)(=O)c2sc(S(N)(=O)=O)cc21   \n",
       "824                                                                                                                                                                                      CCCN(CCOc1c(Cl)cc(Cl)cc1Cl)C(=O)n1ccnc1.O=S(=O)([O-])C(I)I.[Na+]   \n",
       "\n",
       "     Blood and lymphatic system disorders  Cardiac disorders  \\\n",
       "0                                       1                  0   \n",
       "1                                       1                  1   \n",
       "2                                       1                  1   \n",
       "3                                       1                  1   \n",
       "4                                       1                  1   \n",
       "..                                    ...                ...   \n",
       "820                                     1                  1   \n",
       "821                                     1                  1   \n",
       "822                                     1                  1   \n",
       "823                                     1                  1   \n",
       "824                                     1                  1   \n",
       "\n",
       "     Congenital, familial and genetic disorders  Ear and labyrinth disorders  \\\n",
       "0                                             1                            1   \n",
       "1                                             1                            1   \n",
       "2                                             1                            1   \n",
       "3                                             1                            1   \n",
       "4                                             1                            1   \n",
       "..                                          ...                          ...   \n",
       "820                                           1                            1   \n",
       "821                                           1                            1   \n",
       "822                                           1                            1   \n",
       "823                                           1                            1   \n",
       "824                                           1                            1   \n",
       "\n",
       "     Endocrine disorders  Eye disorders  Gastrointestinal disorders  ...  \\\n",
       "0                      1              1                           1  ...   \n",
       "1                      1              1                           1  ...   \n",
       "2                      1              1                           1  ...   \n",
       "3                      1              1                           1  ...   \n",
       "4                      1              1                           1  ...   \n",
       "..                   ...            ...                         ...  ...   \n",
       "820                    0              1                           1  ...   \n",
       "821                    0              1                           1  ...   \n",
       "822                    1              1                           1  ...   \n",
       "823                    1              1                           1  ...   \n",
       "824                    1              1                           1  ...   \n",
       "\n",
       "     Musculoskeletal and connective tissue disorders  \\\n",
       "0                                                  1   \n",
       "1                                                  1   \n",
       "2                                                  1   \n",
       "3                                                  1   \n",
       "4                                                  1   \n",
       "..                                               ...   \n",
       "820                                                1   \n",
       "821                                                1   \n",
       "822                                                1   \n",
       "823                                                1   \n",
       "824                                                1   \n",
       "\n",
       "     Neoplasms benign, malignant and unspecified (incl cysts and polyps)  \\\n",
       "0                                                                      1   \n",
       "1                                                                      1   \n",
       "2                                                                      1   \n",
       "3                                                                      1   \n",
       "4                                                                      1   \n",
       "..                                                                   ...   \n",
       "820                                                                    0   \n",
       "821                                                                    1   \n",
       "822                                                                    1   \n",
       "823                                                                    0   \n",
       "824                                                                    1   \n",
       "\n",
       "     Nervous system disorders  Pregnancy, puerperium and perinatal conditions  \\\n",
       "0                           1                                               1   \n",
       "1                           1                                               1   \n",
       "2                           1                                               1   \n",
       "3                           1                                               1   \n",
       "4                           1                                               1   \n",
       "..                        ...                                             ...   \n",
       "820                         1                                               1   \n",
       "821                         1                                               1   \n",
       "822                         1                                               1   \n",
       "823                         1                                               1   \n",
       "824                         1                                               1   \n",
       "\n",
       "     Psychiatric disorders  Renal and urinary disorders  \\\n",
       "0                        1                            1   \n",
       "1                        1                            1   \n",
       "2                        1                            1   \n",
       "3                        1                            1   \n",
       "4                        1                            1   \n",
       "..                     ...                          ...   \n",
       "820                      0                            0   \n",
       "821                      1                            1   \n",
       "822                      1                            1   \n",
       "823                      1                            1   \n",
       "824                      1                            1   \n",
       "\n",
       "     Reproductive system and breast disorders  \\\n",
       "0                                           1   \n",
       "1                                           1   \n",
       "2                                           1   \n",
       "3                                           1   \n",
       "4                                           1   \n",
       "..                                        ...   \n",
       "820                                         0   \n",
       "821                                         1   \n",
       "822                                         1   \n",
       "823                                         0   \n",
       "824                                         1   \n",
       "\n",
       "     Respiratory, thoracic and mediastinal disorders  \\\n",
       "0                                                  1   \n",
       "1                                                  1   \n",
       "2                                                  1   \n",
       "3                                                  1   \n",
       "4                                                  1   \n",
       "..                                               ...   \n",
       "820                                                1   \n",
       "821                                                1   \n",
       "822                                                1   \n",
       "823                                                1   \n",
       "824                                                1   \n",
       "\n",
       "     Skin and subcutaneous tissue disorders  Vascular disorders  \n",
       "0                                         1                   1  \n",
       "1                                         1                   1  \n",
       "2                                         1                   1  \n",
       "3                                         1                   1  \n",
       "4                                         1                   1  \n",
       "..                                      ...                 ...  \n",
       "820                                       1                   1  \n",
       "821                                       1                   1  \n",
       "822                                       1                   1  \n",
       "823                                       1                   1  \n",
       "824                                       1                   1  \n",
       "\n",
       "[825 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv('dataframes/SIDER_with_isoSMILES.tsv', sep='\\t')\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "a2f55a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_sample_df = df_data.sample(n=400, random_state=42) # for pilot dataset\n",
    "random_sample_df = df_data.sample(n=100) # for pilot dataset\n",
    "# random_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "eb9e357b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(825, 23)\n",
      "(825,)\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "# X = random_sample_df[\"SMILES\"].values\n",
    "# y = random_sample_df.iloc[:, 3:26].values\n",
    "X = df_data[\"SMILES\"].values\n",
    "y = df_data.iloc[:, 3:26].values\n",
    "# X = df_data[\"SMILES\"].values\n",
    "# y = df_data.iloc[:, 4:27].values\n",
    "print(y.shape)\n",
    "print(X.shape)\n",
    "# print(y[:,1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "4c3c2b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = max(1, max(len(sequence) for sequence in X))\n",
    "print(max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "bfbbf888",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Calculate class occurance in the sampled data --##\n",
    "# class_vectors = np.array(y)\n",
    "# class_count = np.sum(class_vectors, axis=0)\n",
    "# print(len(class_count),  class_count, np.sum(class_count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59552ee8",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2377057",
   "metadata": {},
   "source": [
    "Convert our text input data into token indices. This means that every token (we can decide what a token is char, word, sub-word, etc.) is mapped to a unique index which allows us to represent our text as an array of indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9813345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from more_itertools import take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "454972e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    def __init__(self, char_level, num_tokens=None,\n",
    "                 pad_token=\"<PAD>\", oov_token=\"<UNK>\",\n",
    "                 token_to_index=None):\n",
    "        self.char_level = char_level\n",
    "        self.separator = \"\" if self.char_level else \" \"\n",
    "        if num_tokens: num_tokens -= 2 # pad + unk tokens\n",
    "        self.num_tokens = num_tokens\n",
    "        self.pad_token = pad_token\n",
    "        self.oov_token = oov_token\n",
    "        if not token_to_index:\n",
    "            token_to_index = {pad_token: 0, oov_token: 1}\n",
    "        self.token_to_index = token_to_index\n",
    "        self.index_to_token = {v: k for k, v in self.token_to_index.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_to_index)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<Tokenizer(num_tokens={len(self)})>\"\n",
    "\n",
    "    def fit_on_texts(self, texts):\n",
    "        if not self.char_level:\n",
    "            texts = [text.split(\" \") for text in texts]\n",
    "        all_tokens = [token for text in texts for token in text]\n",
    "        counts = Counter(all_tokens).most_common(self.num_tokens)\n",
    "        self.min_token_freq = counts[-1][1]\n",
    "        for token, count in counts:\n",
    "            index = len(self)\n",
    "            self.token_to_index[token] = index\n",
    "            self.index_to_token[index] = token\n",
    "        return self\n",
    "\n",
    "    def texts_to_sequences(self, texts):\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            if not self.char_level:\n",
    "                text = text.split(\" \")\n",
    "            sequence = []\n",
    "            for token in text:\n",
    "                sequence.append(self.token_to_index.get(\n",
    "                    token, self.token_to_index[self.oov_token]))\n",
    "            sequences.append(np.asarray(sequence))\n",
    "        return sequences\n",
    "\n",
    "    def sequences_to_texts(self, sequences):\n",
    "        texts = []\n",
    "        for sequence in sequences:\n",
    "            text = []\n",
    "            for index in sequence:\n",
    "                text.append(self.index_to_token.get(index, self.oov_token))\n",
    "            texts.append(self.separator.join([token for token in text]))\n",
    "        return texts\n",
    "\n",
    "    def save(self, fp):\n",
    "        with open(fp, \"w\") as fp:\n",
    "            contents = {\n",
    "                \"char_level\": self.char_level,\n",
    "                \"oov_token\": self.oov_token,\n",
    "                \"token_to_index\": self.token_to_index\n",
    "            }\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, fp):\n",
    "        with open(fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "        return cls(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "d69eeab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Tokenizer(num_tokens=10)>\n",
      "[('<PAD>', 0), ('<UNK>', 1), ('C', 2), ('N', 3), ('=', 4)]\n",
      "least freq token's freq: 2\n",
      "[array([2, 3, 7, 2, 4, 3, 2, 8, 4, 2, 7, 2, 5, 4, 9, 6, 3, 5, 2, 5, 4, 9,\n",
      "       6, 3, 8, 2, 6, 2])]\n"
     ]
    }
   ],
   "source": [
    "# -- test --#\n",
    "smiles = ['CN1C=NC2=C1C(=O)N(C(=O)N2C)C']\n",
    "tokenizer = Tokenizer(char_level=True, num_tokens=62)\n",
    "tokenizer.fit_on_texts(texts=smiles)\n",
    "VOCAB_SIZE = len(tokenizer)\n",
    "print (tokenizer)\n",
    "print (take(5, tokenizer.token_to_index.items()))\n",
    "print (f\"least freq token's freq: {tokenizer.min_token_freq}\") \n",
    "test = tokenizer.texts_to_sequences(smiles)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "eae975a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Tokenizer(num_tokens=47)>\n",
      "[('<PAD>', 0), ('<UNK>', 1), ('C', 2), ('(', 3), (')', 4)]\n",
      "least freq token's freq: 1\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(char_level=True, num_tokens=62)\n",
    "# tokenizer.fit_on_texts(texts=X_train)\n",
    "tokenizer.fit_on_texts(texts=X)\n",
    "VOCAB_SIZE = len(tokenizer)\n",
    "print (tokenizer)\n",
    "print (take(5, tokenizer.token_to_index.items()))\n",
    "print (f\"least freq token's freq: {tokenizer.min_token_freq}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "bc4b133f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to indices:\n",
      "  (preprocessed) → Nc1nc(=O)c2c([nH]1)NCC(CNc1ccc(C(=O)NC(CCC(=O)O)C(=O)O)cc1)N2C=O\n",
      "  (tokenized) → [13  5 12 16  5  3 10  6  4  5 14  5  3  8 16 11  9 12  4 13  2  2  3  2\n",
      " 13  5 12  5  5  5  3  2  3 10  6  4 13  2  3  2  2  2  3 10  6  4  6  4\n",
      "  2  3 10  6  4  6  4  5  5 12  4 13 14  2 10  6]\n"
     ]
    }
   ],
   "source": [
    "# Convert texts to sequences of indices\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "preprocessed_text = tokenizer.sequences_to_texts([X[0]])[0]\n",
    "print (\"Text to indices:\\n\"\n",
    "    f\"  (preprocessed) → {preprocessed_text}\\n\"\n",
    "    f\"  (tokenized) → {X[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2ce93c",
   "metadata": {},
   "source": [
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636c6036",
   "metadata": {},
   "source": [
    "OHE of the tokens will create matrix with binary values where each vocabulary or tokens will be indicated by 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6402a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(seq, num_classes):\n",
    "    \"\"\"One-hot encode a sequence of tokens.\"\"\"\n",
    "    one_hot = np.zeros((len(seq), num_classes)) # num_classes is the vocabulary size\n",
    "    for i, item in enumerate(seq):\n",
    "        one_hot[i, item] = 1.\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "81beb37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tokens to one-hot\n",
    "vocab_size = len(tokenizer)\n",
    "X = [to_categorical(seq, num_classes=vocab_size) for seq in X]\n",
    "# X_train = [to_categorical(seq, num_classes=vocab_size) for seq in X_train]\n",
    "# X_val = [to_categorical(seq, num_classes=vocab_size) for seq in X_val]\n",
    "# X_test = [to_categorical(seq, num_classes=vocab_size) for seq in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "4a59a91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "64 None\n"
     ]
    }
   ],
   "source": [
    "print(len(X[0]), print(vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c38dfe4",
   "metadata": {},
   "source": [
    "# Padding\n",
    "Our inputs are all of varying length but we need each batch to be uniformly shaped. Therefore, we will use padding to make all the inputs in the batch the same length.\n",
    "\n",
    "Here we will create a batch of shape (N (i.e., sample size), max_seq_len, vocab_size) so we'll need to be able to pad 3D sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "05a11005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, max_seq_len=0): # ACROSS DIFFERENT BATCHES WE CAN MAKE IT CONSISTENT, SAY max_seq_len=382\n",
    "    \"\"\"Pad sequences to max length in sequence.\"\"\"\n",
    "    max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\n",
    "    num_classes = sequences[0].shape[-1]\n",
    "    padded_sequences = np.zeros((len(sequences), max_seq_len, num_classes))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        padded_sequences[i][:len(sequence)] = sequence\n",
    "    return padded_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "d54de6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 47) (141, 47) (174, 47)\n",
      "64\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(3, 174, 47)\n",
      "(174, 47) (174, 47) (174, 47)\n"
     ]
    }
   ],
   "source": [
    "# -- Test -- #\n",
    "print (X[0].shape, X[1].shape, X[2].shape)\n",
    "print(len(X[0]))\n",
    "print(X[0])\n",
    "padded = pad_sequences(X[0:3])\n",
    "print (padded.shape) # (N (i.e., sample size), max_seq_len, vocab_size)\n",
    "print (padded[0].shape, padded[1].shape, padded[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "ab7992c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(824, 398, 47)\n",
      "825\n"
     ]
    }
   ],
   "source": [
    "# -- Create padded dataset with consistent dimension --# \n",
    "padded_X =  pad_sequences(X[0:-1])\n",
    "print(padded_X.shape)\n",
    "print(len(X))\n",
    "# print(X[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafe047e",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "6f446b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "15e1485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, num_filters, filter_size,\n",
    "                 hidden_dim, dropout_p, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # Convolutional filters\n",
    "        self.filter_size = filter_size # we'll used 1d filters like 1x3\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=vocab_size, out_channels=num_filters,\n",
    "            kernel_size=filter_size, stride=1, padding=0, padding_mode=\"zeros\") # padding 0 is no padding\n",
    "        self.batch_norm = nn.BatchNorm1d(num_features=num_filters) \n",
    "\n",
    "        # FC layers\n",
    "        self.fc1 = nn.Linear(num_filters, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()  # Sigmoid activation function for multi-label classification\n",
    "\n",
    "    def forward(self, inputs, channel_first=False,):\n",
    "\n",
    "        # Rearrange input so num_channels is in dim 1 (N, C, L)\n",
    "        # With PyTorch, when dealing with convolution, our inputs (X) need to have the \n",
    "        # channels as the second dimension, so our inputs will be (N, vocab_size, max_seq_len)\n",
    "#         x_in, = inputs\n",
    "        x_in, = [i.squeeze(1) for i in inputs] # when transormation applied but not resizing\n",
    "        if not channel_first:\n",
    "            x_in = x_in.transpose(1, 2)\n",
    "\n",
    "        # Padding for `SAME` padding\n",
    "        max_seq_len = x_in.shape[2] # after transpose, the 3rd dim (i.e. 2) is the seq length\n",
    "        padding_left = int((self.conv.stride[0]*(max_seq_len-1) - max_seq_len + self.filter_size)/2)\n",
    "        padding_right = int(math.ceil((self.conv.stride[0]*(max_seq_len-1) - max_seq_len + self.filter_size)/2))\n",
    "\n",
    "        # Conv outputs\n",
    "        z = self.conv(F.pad(x_in, (padding_left, padding_right)))\n",
    "        z = self.batch_norm(z)  # Batch normalization\n",
    "        z = F.relu(z)  # Activation function\n",
    "        z = F.max_pool1d(z, z.size(2)).squeeze(2) # a 1-dimensional max pooling operation to the input tensor z along its last dimension\n",
    "\n",
    "        # FC layer\n",
    "        z = self.fc1(z)\n",
    "        z = self.dropout(z)\n",
    "        z = self.fc2(z)\n",
    "        z = self.sigmoid(z)  # Sigmoid activation function for multi-label classification\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "7120554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_2d(nn.Module):\n",
    "    def __init__(self,num_filters, dropout_p, num_classes):\n",
    "        super(CNN_2d, self).__init__()\n",
    "\n",
    "        # Convolutional filters\n",
    "#         self.filter_size = filter_size # we'll used 1d filters like 1x3\n",
    "#         self.conv1 = nn.Conv2d(224,num_filters,3)\n",
    "        self.conv1 = nn.Conv2d(1,num_filters,3)\n",
    "        self.conv2 = nn.Conv2d(num_filters,100,3)\n",
    "        self.conv3 = nn.Conv2d(100,num_filters,3)\n",
    "        self.conv4 = nn.Conv2d(num_filters, 10, 3)\n",
    "        \n",
    "        # FC layers\n",
    "        self.fc1 = nn.Linear(5760, 1024)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "#         self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc3 = nn.Linear (512, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "#         self.conv1 = nn.Conv1d(\n",
    "#             in_channels=vocab_size, out_channels=num_filters,\n",
    "#             kernel_size=filter_size, stride=1, padding=0, padding_mode=\"zeros\") # padding 0 is no padding\n",
    "        self.batch_norm1 = nn.BatchNorm2d(num_features=num_filters)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(num_features=100)\n",
    "\n",
    "        # FC layers\n",
    "  \n",
    "\n",
    "    def forward(self, inputs, channel_first=False,):\n",
    "\n",
    "        # Rearrange input so num_channels is in dim 1 (N, C, L)\n",
    "        # With PyTorch, when dealing with convolution, our inputs (X) need to have the \n",
    "        # channels as the second dimension, so our inputs will be (N, vocab_size, max_seq_len)\n",
    "        x_in, = inputs\n",
    "#         if not channel_first:\n",
    "#             x_in = x_in.transpose(1, 2)\n",
    "#             x_in = x_in.transpose(0, 1)\n",
    "\n",
    "        # Padding for `SAME` padding\n",
    "#         max_seq_len = x_in.shape[2] # after transpose, the 3rd dim (i.e. 2) is the seq length\n",
    "#         padding_left = int((self.conv1.stride[0]*(max_seq_len-1) - max_seq_len + 5)/2)\n",
    "#         padding_right = int(math.ceil((self.conv1.stride[0]*(max_seq_len-1) - max_seq_len + 5)/2))\n",
    "\n",
    "        # Conv outputs\n",
    "#         z = self.conv1(F.pad(x_in, (padding_left, padding_right)))\n",
    "        z = x_in\n",
    "        z = F.relu(self.conv1(z))\n",
    "        z = self.batch_norm1(z)  # Batch normalization\n",
    "        z = F.max_pool2d(z, kernel_size = 2, stride = 2)\n",
    "        z = F.relu(self.conv2(z))\n",
    "        z = self.batch_norm2(z)  # Batch normalization\n",
    "        z = F.max_pool2d(z, kernel_size = 2, stride = 2)\n",
    "#         z = self.batch_norm(z)  # Batch normalization\n",
    "        z = F.relu(self.conv3(z))\n",
    "        z = self.batch_norm1(z)  # Batch normalization\n",
    "        z = F.max_pool2d(z, kernel_size = 2, stride = 2)\n",
    "        z = F.relu(self.conv4(z))\n",
    "        \n",
    "        z = torch.flatten(z, start_dim=1)\n",
    "        \n",
    "        z = F.relu(self.fc1(z))\n",
    "        z = self.dropout(z)\n",
    "        z = F.relu(self.fc2(z))\n",
    "        z = self.dropout(z)\n",
    "        z = self.fc3(z)\n",
    "        z = self.sigmoid(z)\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "fd50a36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet1D(\n",
      "  (conv1): Conv1d(1, 64, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)\n",
      "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (fc): Linear(in_features=512, out_features=23, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.stride = stride\n",
    "\n",
    "        # Adjust the dimensions if the number of input channels doesn't match the number of output channels\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Sequential()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        shortcut = self.shortcut(x)\n",
    "\n",
    "        out += shortcut\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet1D(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=23):\n",
    "        super(ResNet1D, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self.make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self.make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self.make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Create a ResNet1D instance\n",
    "model = ResNet1D(ResidualBlock, [2, 2, 2, 2], num_classes=23)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "655f637d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "cuda = True\n",
    "device = torch.device(\"cuda\" if (\n",
    "    torch.cuda.is_available() and cuda) else \"cpu\")\n",
    "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "if device.type == \"cuda\":\n",
    "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de51358",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "ea05d4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "99037315",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Trainer class to run single or multi-CV training (both exmaples are covered at the following)-- #\n",
    "class Trainer(object):\n",
    "    def __init__(self, model, device, loss_fn=None, optimizer=None, scheduler=None):\n",
    "\n",
    "        # Set params\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "    def train_step(self, dataloader):\n",
    "        \"\"\"Train step.\"\"\"\n",
    "        # Set model to train mode\n",
    "        self.model.train()\n",
    "        loss = 0.0\n",
    "\n",
    "        # Iterate over train batches\n",
    "        for i, batch in enumerate(dataloader):\n",
    "\n",
    "            # Step\n",
    "#             batch = [item.to(self.device) for item in batch]  # Set device\n",
    "            # Modify batch to move items to the device\n",
    "#             batch = [[sub_item.squeeze(1).to(device) for sub_item in item] if isinstance(item, list) else item.squeeze(1).to(device) for item in batch]\n",
    "            batch = [[sub_item.to(device) for sub_item in item] if isinstance(item, list) else item.to(device) for item in batch]\n",
    "            inputs, targets = batch[:-1], batch[-1]\n",
    "            self.optimizer.zero_grad()  # Reset gradients\n",
    "            z = self.model(inputs)  # Forward pass\n",
    "#             J = self.loss_fn(z, targets).item()  # Define loss\n",
    "            J = self.loss_fn(z, targets.squeeze(1))  # Define loss\n",
    "            J.backward()  # Backward pass\n",
    "            self.optimizer.step()  # Update weights\n",
    "\n",
    "            # Cumulative Metrics\n",
    "            loss += (J.detach().item() - loss) / (i + 1)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def eval_step(self, dataloader):\n",
    "        \"\"\"Validation or test step.\"\"\"\n",
    "        # Set model to eval mode\n",
    "        self.model.eval()\n",
    "        loss = 0.0\n",
    "        y_trues, y_probs = [], []\n",
    "\n",
    "        # Iterate over val batches\n",
    "        with torch.inference_mode():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "\n",
    "                # Step\n",
    "#                 batch = [item.to(self.device) for item in batch]  # Set device\n",
    "                # Modify batch to move items to the device\n",
    "#                 batch = [[sub_item.squeeze(1).to(device) for sub_item in item] if isinstance(item, list) else item.squeeze(1).to(device) for item in batch]\n",
    "                batch = [[sub_item.to(device) for sub_item in item] if isinstance(item, list) else item.to(device) for item in batch]\n",
    "                inputs, y_true = batch[:-1], batch[-1]\n",
    "\n",
    "                z = self.model(inputs)  # Forward pass\n",
    "#                 J = self.loss_fn(z, y_true).item()\n",
    "                J = self.loss_fn(z, y_true.squeeze(1)).item()\n",
    "\n",
    "                # Cumulative Metrics\n",
    "                loss += (J - loss) / (i + 1)\n",
    "\n",
    "                # Store outputs\n",
    "#                 y_prob = F.softmax(z).cpu().numpy() # probably we don't need this as we already put sigmoid on the output layer\n",
    "                y_prob = z.detach().numpy() # probably this is how we cast tensor to numpy\n",
    "                y_probs.extend(y_prob)\n",
    "                y_trues.extend(y_true.cpu().numpy())\n",
    "\n",
    "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
    "\n",
    "    def predict_step(self, dataloader):\n",
    "        \"\"\"Prediction step.\"\"\"\n",
    "        # Set model to eval mode\n",
    "        self.model.eval()\n",
    "        y_probs = []\n",
    "\n",
    "        # Iterate over val batches\n",
    "        with torch.inference_mode():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "\n",
    "                # Forward pass w/ inputs\n",
    "                inputs, targets = batch[:-1], batch[-1]\n",
    "                z = self.model(inputs)\n",
    "\n",
    "                # Store outputs\n",
    "                y_prob = F.softmax(z).cpu().numpy()\n",
    "                y_probs.extend(y_prob)\n",
    "\n",
    "        return np.vstack(y_probs)\n",
    "\n",
    "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\n",
    "        history = {'train_loss': [], 'test_loss': []}\n",
    "        best_val_loss = np.inf\n",
    "        for epoch in range(num_epochs):\n",
    "            # Steps\n",
    "            train_loss = self.train_step(dataloader=train_dataloader)\n",
    "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
    "            self.scheduler.step(val_loss)\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = self.model\n",
    "                _patience = patience  # reset _patience\n",
    "            else:\n",
    "                _patience -= 1\n",
    "            if not _patience:  # 0\n",
    "                print(\"Stopping early!\")\n",
    "                break\n",
    "\n",
    "            # Logging\n",
    "            print(\n",
    "                f\"Epoch: {epoch+1} | \"\n",
    "                f\"train_loss: {train_loss:.5f}, \"\n",
    "                f\"val_loss: {val_loss:.5f}, \"\n",
    "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
    "                f\"_patience: {_patience}\"\n",
    "            )\n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['test_loss'].append(val_loss)\n",
    "        avg_train_loss = np.mean(history['train_loss'])\n",
    "        avg_test_loss = np.mean(history['test_loss'])\n",
    "#         print(avg_train_loss,avg_test_loss)\n",
    "        return best_model, avg_train_loss, avg_test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b9753c",
   "metadata": {},
   "source": [
    "# Dataset processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "7b54f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this class includes sampling from different folds (its suitable for dataset creation when we're already\n",
    "# applying transformation to the pre-padded dataset and passing it through dataloader ) ##\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, max_filter_size, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.max_filter_size = max_filter_size # this is padding arguement\n",
    "#         self.sampler = sampler # sampling list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<Dataset(N={len(self)})>\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        y = self.y[index]\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        return X, y\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"Custom collate function.\"\"\"\n",
    "        batch_X = [item[0] for item in batch]\n",
    "        batch_y = [item[1] for item in batch]\n",
    "\n",
    "        # Pad sequences (if necessary)\n",
    "#         batch_X = pad_sequences(batch_X, max_seq_len=self.max_filter_size) # padding for consistent dimensions for each input batch\n",
    "\n",
    "\n",
    "        # Convert batch_y to tensors and reshape\n",
    "#         batch_y = torch.stack([torch.LongTensor(y).view(1, -1) for y in batch_y], dim=0)\n",
    "#         batch_y = torch.stack([torch.FloatTensor(y).view(1, -1) for y in batch_y], dim=0)\n",
    "        batch_y = torch.stack([torch.tensor(y, dtype=torch.float32).unsqueeze(0) for y in batch_y], dim=0)\n",
    "\n",
    "\n",
    "        # Cast\n",
    "#         batch_X = torch.FloatTensor(batch_X) # float because input is kind of continuous in the pixel space\n",
    "        batch_X = torch.stack(batch_X)\n",
    "\n",
    "        return batch_X, batch_y\n",
    "\n",
    "\n",
    "    def create_dataloader(self, batch_size, sampler=None, shuffle=False, drop_last=True):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset=self, batch_size=batch_size, sampler=sampler, collate_fn=self.collate_fn,\n",
    "            shuffle=shuffle, drop_last=drop_last, pin_memory=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d3e4be",
   "metadata": {},
   "source": [
    "# K-fold CV - data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "1a7421d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import random\n",
    "from torch.utils.data import random_split,SubsetRandomSampler, ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "31de6f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5\n",
    "splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "# splits=StratifiedKFold(n_splits=k,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "3bf9c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "9cedec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:  1\n",
      "2\n",
      "1 torch.Size([32, 1, 224, 224])\n",
      "32 torch.Size([1, 23])\n",
      "torch.Size([32, 224, 224])\n",
      "torch.Size([32, 1, 23])\n",
      "count:  2\n",
      "2\n",
      "1 torch.Size([32, 1, 224, 224])\n",
      "32 torch.Size([1, 23])\n",
      "torch.Size([32, 224, 224])\n",
      "torch.Size([32, 1, 23])\n",
      "count:  3\n",
      "2\n",
      "1 torch.Size([32, 1, 224, 224])\n",
      "32 torch.Size([1, 23])\n",
      "torch.Size([32, 224, 224])\n",
      "torch.Size([32, 1, 23])\n",
      "count:  4\n",
      "2\n",
      "1 torch.Size([32, 1, 224, 224])\n",
      "32 torch.Size([1, 23])\n",
      "torch.Size([32, 224, 224])\n",
      "torch.Size([32, 1, 23])\n",
      "count:  5\n",
      "2\n",
      "1 torch.Size([32, 1, 224, 224])\n",
      "32 torch.Size([1, 23])\n",
      "torch.Size([32, 224, 224])\n",
      "torch.Size([32, 1, 23])\n",
      "count:  6\n",
      "2\n",
      "1 torch.Size([32, 1, 224, 224])\n",
      "32 torch.Size([1, 23])\n",
      "torch.Size([32, 224, 224])\n",
      "torch.Size([32, 1, 23])\n",
      "count:  7\n",
      "2\n",
      "1 torch.Size([32, 1, 224, 224])\n",
      "32 torch.Size([1, 23])\n",
      "torch.Size([32, 224, 224])\n",
      "torch.Size([32, 1, 23])\n",
      "count:  8\n",
      "2\n",
      "1 torch.Size([32, 1, 224, 224])\n",
      "32 torch.Size([1, 23])\n",
      "torch.Size([32, 224, 224])\n",
      "torch.Size([32, 1, 23])\n",
      "count:  9\n",
      "2\n",
      "1 torch.Size([32, 1, 224, 224])\n",
      "32 torch.Size([1, 23])\n",
      "torch.Size([32, 224, 224])\n",
      "torch.Size([32, 1, 23])\n",
      "count:  10\n",
      "2\n",
      "1 torch.Size([32, 1, 224, 224])\n",
      "32 torch.Size([1, 23])\n",
      "torch.Size([32, 224, 224])\n",
      "torch.Size([32, 1, 23])\n",
      "count:  11\n",
      "2\n",
      "1 torch.Size([32, 1, 224, 224])\n",
      "32 torch.Size([1, 23])\n",
      "torch.Size([32, 224, 224])\n",
      "torch.Size([32, 1, 23])\n",
      "count:  12\n",
      "2\n",
      "1 torch.Size([32, 1, 224, 224])\n",
      "32 torch.Size([1, 23])\n",
      "torch.Size([32, 224, 224])\n",
      "torch.Size([32, 1, 23])\n",
      "count:  13\n",
      "2\n",
      "1 torch.Size([32, 1, 224, 224])\n",
      "32 torch.Size([1, 23])\n",
      "torch.Size([32, 224, 224])\n",
      "torch.Size([32, 1, 23])\n",
      "count:  14\n",
      "2\n",
      "1 torch.Size([32, 1, 224, 224])\n",
      "32 torch.Size([1, 23])\n",
      "torch.Size([32, 224, 224])\n",
      "torch.Size([32, 1, 23])\n",
      "count:  15\n",
      "2\n",
      "1 torch.Size([32, 1, 224, 224])\n",
      "32 torch.Size([1, 23])\n",
      "torch.Size([32, 224, 224])\n",
      "torch.Size([32, 1, 23])\n",
      "count:  16\n",
      "2\n",
      "1 torch.Size([32, 1, 224, 224])\n",
      "32 torch.Size([1, 23])\n",
      "torch.Size([32, 224, 224])\n",
      "torch.Size([32, 1, 23])\n",
      "count:  17\n",
      "2\n",
      "1 torch.Size([32, 1, 224, 224])\n",
      "32 torch.Size([1, 23])\n",
      "torch.Size([32, 224, 224])\n",
      "torch.Size([32, 1, 23])\n",
      "count:  18\n",
      "2\n",
      "1 torch.Size([32, 1, 224, 224])\n",
      "32 torch.Size([1, 23])\n",
      "torch.Size([32, 224, 224])\n",
      "torch.Size([32, 1, 23])\n",
      "count:  19\n",
      "2\n",
      "1 torch.Size([32, 1, 224, 224])\n",
      "32 torch.Size([1, 23])\n",
      "torch.Size([32, 224, 224])\n",
      "torch.Size([32, 1, 23])\n",
      "count:  20\n",
      "2\n",
      "1 torch.Size([32, 1, 224, 224])\n",
      "32 torch.Size([1, 23])\n",
      "torch.Size([32, 224, 224])\n",
      "torch.Size([32, 1, 23])\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    c = c+1\n",
    "    print(\"count: \", c)\n",
    "#     batch = [[sub_item.squeeze(1).to(device) for sub_item in item] if isinstance(item, list) else item.squeeze(1).to(device) for item in batch]\n",
    "    batch = [[sub_item.to(device) for sub_item in item] if isinstance(item, list) else item.to(device) for item in batch]\n",
    "    inputs, y_true = batch[:-1], batch[-1]\n",
    "#     x_in, = inputs\n",
    "    x_in, = [i.squeeze(1) for i in inputs]\n",
    "    x_in = x_in.transpose(1, 2)\n",
    "#     z = model(x_in)  # Forward pass\n",
    "#                 J = self.loss_fn(z, y_true).item()\n",
    "#     J = self.loss_fn(z, y_true.squeeze(1)).item()\n",
    "    print(len(batch))\n",
    "#     print(batch[0].shape, batch[1].shape)\n",
    "    print(len(inputs), inputs[0].shape)\n",
    "    print(len(y_true), y_true[0].shape)\n",
    "    print(x_in.shape)\n",
    "#     print(z.shape)\n",
    "    print(y_true.shape)\n",
    "\n",
    "\n",
    "# for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(X)))):\n",
    "#     train_data_X = []\n",
    "#     train_data_y = []\n",
    "#     test_data_X = []\n",
    "#     test_data_y = []\n",
    "\n",
    "#     print('Fold {}'.format(fold + 1))\n",
    "    \n",
    "#     for i in train_idx:  \n",
    "#         train_data_X.append(padded_X[i-1].astype(np.uint8))\n",
    "#         train_data_y.append(y[i-1,:].astype(np.uint8))\n",
    "    \n",
    "#     for j in val_idx:\n",
    "#         test_data_X.append(padded_X[j-1].astype(np.uint8))\n",
    "#         test_data_y.append(y[j-1,:].astype(np.uint8))\n",
    "#     train_dataset = Dataset(X=train_data_X, y=train_data_y, max_filter_size=400, transform=train_transforms) \n",
    "#     test_dataset = Dataset(X=test_data_X, y=test_data_y, max_filter_size=400, transform=train_transforms) \n",
    "#     print(len(train_data_X), len(train_data_y))\n",
    "#     print(len(test_data_X), len(test_data_y))\n",
    "#     print(train_dataset[0][0].shape, test_dataset[0][0].shape)\n",
    "#     print(train_dataset[0][1].shape, test_dataset[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "f21663d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(X), y.shape)\n",
    "# print(X[0])\n",
    "# print(X[i].astype(np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "a98599cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is necessary as our dataset is massively skewed to positives for all classes\n",
    "def calculate_pos_weights(data): # data = labels\n",
    "#     class_vectors = np.array(data)\n",
    "    class_counts = np.sum(data, axis=0)\n",
    "#     pos_weights = np.ones_like(class_counts)\n",
    "    neg_counts = [len(data)-pos_count for pos_count in class_counts]\n",
    "    pos_weights = []\n",
    "    for i in range(len(class_counts)):\n",
    "        pos_weights.append(neg_counts[i]/ class_counts[i] + 1e-5)\n",
    "    return torch.as_tensor(np.array(pos_weights), dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "cc6d706a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "NUM_FILTERS = 50\n",
    "HIDDEN_DIM = 300\n",
    "DROPOUT_P = 0.2\n",
    "FILTER_SIZE = 3\n",
    "# NUM_CLASSES = test_dataset[0][1].shape[0]\n",
    "NUM_CLASSES = y.shape[1]\n",
    "print(NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "59fffc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "# model = CNN(vocab_size=224, num_filters=NUM_FILTERS, filter_size=FILTER_SIZE,\n",
    "#             hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)\n",
    "# model = CNN(vocab_size=224, num_filters=NUM_FILTERS, filter_size=FILTER_SIZE,\n",
    "#             hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)\n",
    "# model = CNN_2d(num_filters=NUM_FILTERS, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)\n",
    "# model = model.to(device) # set device\n",
    "# print (model.named_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "b04fda76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0550, 0.0591, 0.0827, 0.2009, 0.1587, 0.0300, 0.0061, 0.0073, 0.1411,\n",
      "        0.0160, 0.0123, 0.0037, 0.0813, 0.0274, 0.1702, 0.0135, 0.0404, 0.0645,\n",
      "        0.0870, 0.0673, 0.0274, 0.0160, 0.0061])\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "PATIENCE = 10\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "# --define class weights\n",
    "class_weights = calculate_pos_weights(data=y) # positive weights\n",
    "print(class_weights)\n",
    "\n",
    "#--Define Loss\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "\n",
    "#--Define optimizer & scheduler\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.1, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "85ef6872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: [16, 49, 38]\n",
    "#  y: [16, 1, 23]\n",
    "# print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "59faaafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Sample batch:\n",
      "  X: [32, 1, 224, 224]\n",
      "  y: [32, 1, 23]\n",
      "  X_shape: (torch.Size([1, 224, 224]), torch.Size([1, 224, 224]))\n",
      "  y_shape: (torch.Size([1, 23]), torch.Size([1, 23]))\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "conv1d() received an invalid combination of arguments - got (list, Parameter, NoneType, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!list!, !Parameter!, !NoneType!, !tuple!, !tuple!, !tuple!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!list!, !Parameter!, !NoneType!, !tuple!, !tuple!, !tuple!, int)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [574]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m batch_X, batch_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(val_dataloader))\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample batch:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  X: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(batch_X\u001b[38;5;241m.\u001b[39msize())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  y: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(batch_y\u001b[38;5;241m.\u001b[39msize())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  X_shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_X[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, batch_X[\u001b[38;5;241m10\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  y_shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_y[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, batch_y[\u001b[38;5;241m10\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m best_model, avg_train_loss,avg_test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATIENCE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPerformance of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fold:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Training Loss: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m Average Test Loss: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(avg_train_loss,avg_test_loss)) \n",
      "Input \u001b[0;32mIn [559]\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, num_epochs, patience, train_dataloader, val_dataloader)\u001b[0m\n\u001b[1;32m     94\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minf\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# Steps\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     val_loss, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_step(dataloader\u001b[38;5;241m=\u001b[39mval_dataloader)\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mstep(val_loss)\n",
      "Input \u001b[0;32mIn [559]\u001b[0m, in \u001b[0;36mTrainer.train_step\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m     26\u001b[0m             inputs, targets \u001b[38;5;241m=\u001b[39m batch[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], batch[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     27\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Reset gradients\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m             z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#             J = self.loss_fn(z, targets).item()  # Define loss\u001b[39;00m\n\u001b[1;32m     30\u001b[0m             J \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(z, targets\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Define loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [568]\u001b[0m, in \u001b[0;36mResNet1D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 64\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[1;32m     66\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py:307\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py:303\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    301\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    302\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: conv1d() received an invalid combination of arguments - got (list, Parameter, NoneType, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!list!, !Parameter!, !NoneType!, !tuple!, !tuple!, !tuple!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!list!, !Parameter!, !NoneType!, !tuple!, !tuple!, !tuple!, int)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "from sklearn.metrics import hamming_loss, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "k=5\n",
    "splits=KFold(n_splits=k,shuffle=True)\n",
    "# splits=StratifiedKFold(n_splits=k,shuffle=True) # Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead.. so we cannot use it\n",
    "\n",
    "\n",
    "# Trainer module\n",
    "trainer = Trainer(\n",
    "    model=model, device=device, loss_fn=loss_fn,\n",
    "    optimizer=optimizer, scheduler=scheduler)\n",
    "\n",
    "    \n",
    "history = {'Hamming loss': [], 'miP': [], 'miR': [], 'miF1': [], 'maP': [], 'maR': [], 'maF1': [], 'micro_auc': [], 'macro_auc': [] }\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(X)))):\n",
    "    train_data_X = []\n",
    "    train_data_y = []\n",
    "    test_data_X = []\n",
    "    test_data_y = []\n",
    "\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "    \n",
    "    for i in train_idx:  \n",
    "#         train_data_X.append(X[i].astype(np.uint8))\n",
    "#         train_data_y.append(y[i,:].astype(np.uint8))\n",
    "     # -- sampling from already padded dataframe --#\n",
    "        train_data_X.append(padded_X[i-1].astype(np.uint8))\n",
    "        train_data_y.append(y[i-1,:].astype(np.uint8))\n",
    "    \n",
    "    for j in val_idx:\n",
    "#         test_data_X.append(X[j].astype(np.uint8))\n",
    "#         test_data_y.append(y[j,:].astype(np.uint8))\n",
    "     # -- sampling from already padded dataframe --#\n",
    "        test_data_X.append(padded_X[j-1].astype(np.uint8))\n",
    "        test_data_y.append(y[j-1,:].astype(np.uint8))\n",
    "    \n",
    "    train_dataset = Dataset(X=train_data_X, y=train_data_y, max_filter_size=400, transform=train_transforms) \n",
    "    test_dataset = Dataset(X=test_data_X, y=test_data_y, max_filter_size=400, transform=test_transforms)\n",
    "#     print(len(train_dataset))\n",
    "#     print(len(test_dataset))\n",
    "    \n",
    "    train_dataloader = train_dataset.create_dataloader(batch_size=batch_size)\n",
    "    val_dataloader = test_dataset.create_dataloader(batch_size=batch_size)\n",
    "    batch_X, batch_y = next(iter(val_dataloader))\n",
    "    print (\"Sample batch:\\n\"\n",
    "    f\"  X: {list(batch_X.size())}\\n\"\n",
    "    f\"  y: {list(batch_y.size())}\\n\"\n",
    "    f\"  X_shape: {batch_X[0].shape, batch_X[10].shape}\\n\"\n",
    "    f\"  y_shape: {batch_y[0].shape, batch_y[10].shape}\\n\")\n",
    "    \n",
    "    best_model, avg_train_loss,avg_test_loss = trainer.train(\n",
    "        NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)\n",
    "    \n",
    "    print(f'Performance of {fold} fold:')\n",
    "    print(\"Average Training Loss: {:.4f} \\t Average Test Loss: {:.4f} \".format(avg_train_loss,avg_test_loss)) \n",
    "    \n",
    "    # For evaluation\n",
    "    test_loss, y_true, y_pred_prob = trainer.eval_step(dataloader=val_dataloader)\n",
    "\n",
    "    # 2. Apply thresholding to convert probabilities to binary predictions\n",
    "    threshold = 0.5\n",
    "    y_pred_binary = (y_pred_prob > threshold).astype(float)\n",
    "\n",
    "    # 3. Calculate evaluation metrics\n",
    "    hamming_loss_value = hamming_loss(y_true, y_pred_binary)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred_binary, average='micro')\n",
    "    ma_precision, ma_recall, ma_f1, _ = precision_recall_fscore_support(y_true, y_pred_binary, average='macro')\n",
    "    \n",
    "    # Macro-average AUC\n",
    "    if np.sum(np.all(y_true == 1, axis=0)) > 0: ## this is needed because macro auc cannot be calculated if one label of all samples belong to either +ve/-ve\n",
    "        # Find cols where every element is 1\n",
    "        columns_to_remove = np.all(y_true == 1, axis=0)\n",
    "\n",
    "        # Remove those rows\n",
    "        y_true_filtered = y_true[:, ~columns_to_remove]\n",
    "        y_pred_filtered = y_pred_prob[:, ~columns_to_remove]\n",
    "        macro_auc = roc_auc_score(y_true_filtered, y_pred_filtered, average='macro')\n",
    "        print(f'done maauc but with {np.sum(np.all(y_true == 1, axis=0))} labels removed')\n",
    "    else:\n",
    "        macro_auc = roc_auc_score(y_true, y_pred_prob, average='macro')\n",
    "        print('done maauc') \n",
    "    \n",
    "    # Micro-auc\n",
    "    try:\n",
    "        micro_auc = roc_auc_score(y_true.ravel(), y_pred_prob.ravel(), average='micro', multi_class='ovr')\n",
    "        print('done miauc')\n",
    "    except ValueError:\n",
    "        pass\n",
    "#     micro_auc = roc_auc_score(y_true, y_pred_prob)\n",
    "\n",
    "#     # Macro-average AUC\n",
    "#     macro_auc = roc_auc_score(y_true, y_pred_prob, average='macro')\n",
    "#     print('done maauc')\n",
    "\n",
    "    history['Hamming loss'].append(hamming_loss_value)\n",
    "    history['miP'].append(precision)\n",
    "    history['miR'].append(recall)\n",
    "    history['miF1'].append(f1)\n",
    "    history['maP'].append(ma_precision)\n",
    "    history['maR'].append(ma_recall)\n",
    "    history['maF1'].append(ma_f1)\n",
    "    history['micro_auc'].append(micro_auc)\n",
    "    history['macro_auc'].append(macro_auc)\n",
    "    # Print or use the evaluation metrics as needed\n",
    "    print(\"Hamming Loss: {:.4f} \\t miP: {:.4f} \\t miR: {:.4f} \\t miF1: {:.4f} \\t maP: {:.4f} \\t maR: {:.4f} \\t maF1: {:.4f} \\t micro_auc: {:.4f} \\t macros_auc: {:.4f} \".format(hamming_loss_value, precision, recall, f1, ma_precision, ma_recall, ma_f1, micro_auc, macro_auc))\n",
    "    \n",
    "\n",
    "# print(train_dataset[742])\n",
    "# print(train_dataset[742][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "id": "9df795d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "7bbde4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average performance over all folds: \n",
      "Hamming Loss: 0.6928260869565217\n",
      "miP: 0.9868105415691197\n",
      "miR: 0.2722008419312977\n",
      "miF1: 0.42624270710277246\n",
      "maP: 0.8014362388312268\n",
      "maR: 0.2650477337049506\n",
      "maF1: 0.3635958786167487\n",
      "micro_auc: 0.7217419779929172\n",
      "macro_auc: 0.7183479796382202\n"
     ]
    }
   ],
   "source": [
    "print(\"Average performance over all folds: \".format(avg_train_loss,avg_test_loss))\n",
    "\n",
    "print(\"Hamming Loss:\", np.mean(history['Hamming loss']))\n",
    "print(\"miP:\", np.mean(history['miP']))\n",
    "print(\"miR:\", np.mean(history['miR']))\n",
    "print(\"miF1:\", np.mean(history['miF1']))\n",
    "print(\"maP:\", np.mean(history['maP']))\n",
    "print(\"maR:\", np.mean(history['maR']))\n",
    "print(\"maF1:\", np.mean(history['maF1']))\n",
    "print(\"micro_auc:\", np.mean(history['micro_auc']))\n",
    "print(\"macro_auc:\", np.mean(history['macro_auc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "142169d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(y_true.shape[0]):\n",
    "#     print(y_true[i], y_pred_binary[i])\n",
    "#     print(y_pred_prob[i])\n",
    "# test_loss, y_true, y_pred_prob = trainer.eval_step(dataloader=val_dataloader)\n",
    "# print(y_true[:9])\n",
    "# print(y_pred_prob[:9])\n",
    "# print(np.sum(y_pred_prob, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3334cd",
   "metadata": {},
   "source": [
    "To do:\n",
    "\n",
    "1. run a better 1d Conv model with the same data aug\n",
    "2. run a 1d resnet\n",
    "2. run without resizing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
